{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and normalize pixel values\n",
    "data = sio.loadmat('mnist_10digits.mat')\n",
    "xtrain = data['xtrain'].T/255\n",
    "ytrain = data['ytrain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_l2(data):\n",
    "    # data: 784 x m array of handwritten digits\n",
    "    m = data.shape[1]\n",
    "    k = 10\n",
    "    # Randomly select k data points to use as initial centroids\n",
    "    centroid = xtrain[:, np.random.choice(m, k)]\n",
    "    \n",
    "    c_old = np.copy(centroid) + 10\n",
    "    n_iter = 0 # Track number of iterations\n",
    "    \n",
    "    while np.linalg.norm(centroid - c_old, ord='fro') > 1e-2:\n",
    "        # Assign each data point to a centroid\n",
    "        c2 = np.sum(np.power(centroid,2), axis=0, keepdims=True)\n",
    "        diff = -2*np.dot(data.T, centroid) + c2\n",
    "        labels = np.argmin(diff, axis=1)\n",
    "        \n",
    "        # Adjust the centroid locations\n",
    "        c_old = np.copy(centroid)\n",
    "        bEmpty = False # Boolean for tracking whether any clusters are empty\n",
    "        \n",
    "        for c in range(centroid.shape[1]):\n",
    "            count = np.count_nonzero(labels == c)\n",
    "            if count == 0:\n",
    "                bEmpty = True\n",
    "                continue\n",
    "            avg = np.mean(data.T[labels == c], axis=0)\n",
    "            centroid[:,c] = avg\n",
    "            \n",
    "        if bEmpty:\n",
    "            # Find the empty clusters\n",
    "            c_empty = np.delete(np.arange(0,k,1),np.unique(labels))\n",
    "            # Remove the centroids and recalculate k\n",
    "            centroid = np.delete(centroid, c_empty, axis=0)\n",
    "            c_old = np.delete(c_old, c_empty, axis=0)\n",
    "            k = centroid.shape[1]\n",
    "        \n",
    "        n_iter += 1\n",
    "        \n",
    "    # Calculate purity of each cluster\n",
    "    purity = []\n",
    "    for c in np.unique(labels):\n",
    "        # Get actual labels for points in each cluster from ytrain\n",
    "        true_labels = ytrain.reshape(60000)[labels == c]\n",
    "        mode = st.mode(true_labels)\n",
    "        p = len(true_labels[true_labels == mode])/len(true_labels)\n",
    "        purity.append(p)\n",
    "    \n",
    "    return labels, centroid, n_iter, purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels, centroid, n_iter, purity = kmeans_l2(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of cluster 0: 0.508\n",
      "Purity of cluster 1: 0.516\n",
      "Purity of cluster 2: 0.424\n",
      "Purity of cluster 3: 0.525\n",
      "Purity of cluster 4: 0.562\n",
      "Purity of cluster 5: 0.755\n",
      "Purity of cluster 6: 0.351\n",
      "Purity of cluster 7: 0.919\n",
      "Purity of cluster 8: 0.663\n",
      "Purity of cluster 9: 0.404\n"
     ]
    }
   ],
   "source": [
    "for p in range(len(purity)):\n",
    "    print('Purity of cluster {}: {}'.format(p,round(purity[p],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_l1(data):\n",
    "    # K-means clustering using Manhattan distance\n",
    "    # data: 784 x m array of handwritten digits\n",
    "    m = data.shape[1]\n",
    "    k = 10\n",
    "    # Randomly select k data points to use as initial centroids\n",
    "    centroid = xtrain[:, np.random.choice(m, k)]\n",
    "    \n",
    "    c_old = np.copy(centroid) + 10\n",
    "    n_iter = 0 # Track number of iterations\n",
    "    \n",
    "    while np.linalg.norm(centroid - c_old, ord='fro') > 1e-1:\n",
    "        diff = np.ndarray((centroid.shape[1],m), dtype=np.double)\n",
    "        # Assign each data point to a centroid\n",
    "        for c in range(centroid.shape[1]):\n",
    "            diff[c,:] = np.sum(np.absolute(data - centroid[:,c].reshape(784,1)), axis=0)\n",
    "        labels = np.argmin(diff, axis=0)\n",
    "        \n",
    "        # Adjust the centroid locations\n",
    "        c_old = np.copy(centroid)\n",
    "        bEmpty = False # Boolean for tracking whether any clusters are empty\n",
    "        \n",
    "        for c in range(centroid.shape[1]):\n",
    "            count = np.count_nonzero(labels == c)\n",
    "            if count == 0:\n",
    "                bEmpty = True\n",
    "                continue\n",
    "            #totals = np.sum(data.T[labels == c], axis=0)\n",
    "            #avg = totals/count\n",
    "            avg = np.median(data.T[labels == c], axis=0)\n",
    "            centroid[:,c] = avg\n",
    "            \n",
    "        if bEmpty:\n",
    "            # Find the empty clusters\n",
    "            c_empty = np.delete(np.arange(0,k,1),np.unique(labels))\n",
    "            # Remove the centroids and recalculate k\n",
    "            centroid = np.delete(centroid, c_empty, axis=0)\n",
    "            c_old = np.delete(c_old, c_empty, axis=0)\n",
    "            k = centroid.shape[1]\n",
    "        \n",
    "        n_iter += 1\n",
    "        \n",
    "    # Calculate purity of each cluster\n",
    "    purity = []\n",
    "    for c in np.unique(labels):\n",
    "        # Get actual labels for points in each cluster from ytrain\n",
    "        true_labels = ytrain.reshape(60000)[labels == c]\n",
    "        mode = st.mode(true_labels)\n",
    "        p = len(true_labels[true_labels == mode])/len(true_labels)\n",
    "        purity.append(p)\n",
    "        \n",
    "    return labels, centroid, n_iter, purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "# Note: may take several minutes to run\n",
    "labels, centroid, n_iter, purity = kmeans_l1(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity of cluster 0: 0.747\n",
      "Purity of cluster 1: 0.41\n",
      "Purity of cluster 2: 0.214\n",
      "Purity of cluster 3: 0.583\n",
      "Purity of cluster 4: 0.503\n",
      "Purity of cluster 5: 0.533\n",
      "Purity of cluster 6: 0.494\n",
      "Purity of cluster 7: 0.929\n",
      "Purity of cluster 8: 0.558\n",
      "Purity of cluster 9: 0.376\n"
     ]
    }
   ],
   "source": [
    "for p in range(len(purity)):\n",
    "    print('Purity of cluster {}: {}'.format(p,round(purity[p],3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
